%******************************************************************************
%
%    ideas.tex  Composition Tree Design Ideas
%
%    File      : $HeadURL:: https://subversion.sfac.auckland.ac.nz/svn/prj_m#$:
%    Author    : Henrik B‰‰rnhielm and Eamonn O'Brien
%    Dev start : 2008-04-09
%
%    Version   : $Revision:: 1330                                            $:
%    Date      : $Date:: 2008-11-01 01:51:44 +1100 (Sat, 01 Nov 2008)        $:
%    Last edit : $Author:: jbaa004                                           $:
%
%    $Id:: ideas.tex 1330 2008-10-31 14:51:44Z jbaa004                       $:
%
%******************************************************************************

\documentclass[twoside,a4paper,reqno,psamsfonts]{amsart}
%\usepackage[swedish,english]{babel} 
\usepackage[latin1]{inputenc} % svenska tecken skall tolkas
%\usepackage{amsmath}
%\usepackage{amsfonts} % for \mathbb
%\usepackage{amsthm}
\usepackage{amscd}
\usepackage{amsopn}
\usepackage{amstext}
\usepackage{amsxtra}
\usepackage{amssymb}
\usepackage{stmaryrd}
\usepackage{upref}
\usepackage{textcase} % For correct case of swedish chars
%\usepackage[algo2e,ruled,linesnumbered,algosection]{algorithm2e} % for typesetting algorithms
%\usepackage{clrscode}
%\renewcommand{\Comment}{$\hspace*{-0.075em} //$ } % Use // for comments
\usepackage{bm} % for \boldsymbol
%\usepackage{draftcopy}
\usepackage{graphicx}
\usepackage{setspace}
\frenchspacing

%\numberwithin{section}{chapter}
\numberwithin{equation}{section}
\numberwithin{figure}{section}
%\numberwithin{algorithm}{chapter}

%\newcounter{algorithm}
%\numberwithin{algorithm}{section}
%\renewcommand{\thealgorithm}{\arabic{section}.\arabic{algorithm}}

\theoremstyle{plain}
\newtheorem{thm}{Theorem}[section]
\newtheorem{lem}[thm]{Lemma}
\newtheorem{cl}[thm]{Corollary}
\newtheorem{pr}[thm]{Proposition}
\newtheorem{axiom}[thm]{Axiom}
\newtheorem{conj}[thm]{Conjecture}

\theoremstyle{definition}
\newtheorem{deff}[thm]{Definition}

\theoremstyle{remark}
\newtheorem{note}[thm]{Note}
\newtheorem{rem}[thm]{Remark}

%\renewcommand{\thetheorem}{Theorem~\arabic{chapter}.\arabic{theorem}}
%\renewcommand{\thepr}{Proposition~\arabic{chapter}.\arabic{pr}}
%\renewcommand{\thedeff}{Definition~\arabic{chapter}.\arabic{deff}}
\providecommand{\abs}[1]{\left\lvert #1 \right\rvert}
\providecommand{\norm}[1]{\left\lVert #1 \right\rVert}
\providecommand{\ceil}[1]{\left\lceil #1 \right\rceil}
\providecommand{\floor}[1]{\lfloor #1 \rfloor}
\providecommand{\set}[1]{\left\lbrace #1 \right\rbrace}
\providecommand{\gen}[1]{\left\langle #1 \right\rangle}
%\providecommand{\ord}[1]{\operatorname{ord}( #1 )}
\providecommand{\Sym}[1]{\operatorname{Sym}( #1 )}
\renewcommand{\Pr}[1]{\operatorname{Pr}[ #1 ]}
%\renewcommand{\char}[1]{\operatorname{char}[ #1 ]}

\newcommand{\field}[1]{\mathbb{#1}}
\newcommand{\vect}[1]{\boldsymbol{\mathrm{#1}}}
\newcommand{\N}{\field{N}}
\newcommand{\Z}{\field{Z}}
\newcommand{\R}{\field{R}}
\newcommand{\Q}{\field{Q}}
\newcommand{\OO}{\field{O}}
\newcommand{\K}{\field{K}}
\newcommand{\A}{\field{A}}
\newcommand{\F}{\field{F}}
\newcommand{\PS}{\field{P}}
\newcommand{\GAP}{\textsf{GAP}}
\newcommand{\MAGMA}{\textsc{Magma}}

% for Cayley graphs
\newcommand{\C}{\mathcal{C}}
\newcommand{\OV}{\mathcal{O}}

\DeclareMathOperator{\sgd}{sgd}
\DeclareMathOperator{\mgm}{mgm}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\GL}{GL}
\DeclareMathOperator{\PGL}{PGL}
\DeclareMathOperator{\GF}{GF}
\DeclareMathOperator{\IM}{Im}
\DeclareMathOperator{\RE}{Re}
\DeclareMathOperator{\I}{Id}
%\DeclareMathOperator{\OR}{O}
\DeclareMathOperator{\SL}{SL}
\DeclareMathOperator{\GO}{GO}
\DeclareMathOperator{\SO}{SO}
\DeclareMathOperator{\Sz}{Sz}
\DeclareMathOperator{\Sp}{Sp}
\DeclareMathOperator{\chr}{char}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Alt}{Alt}
\DeclareMathOperator{\PSL}{PSL}
\DeclareMathOperator{\PPSL}{(P)SL}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\SLP}{\mathtt{SLP}}
\DeclareMathOperator{\G2}{{^2}G_2}
\DeclareMathOperator{\LargeRee}{{^2}F_4}
\DeclareMathOperator{\Ree}{Ree}
\DeclareMathOperator{\Gal}{Gal}
\DeclareMathOperator{\Norm}{N}
\DeclareMathOperator{\Cent}{C}
\DeclareMathOperator{\Zent}{Z}
\DeclareMathOperator{\EndR}{End}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\cln}{{:}}
\DeclareMathOperator{\O2}{O_2}
\DeclareMathOperator{\Op}{O_p}
\DeclareMathOperator{\RP}{\bf{RP}}
\DeclareMathOperator{\NP}{\bf{NP}}
\DeclareMathOperator{\PP}{\bf{P}}
\DeclareMathOperator{\coRP}{\bf{co-RP}}
\DeclareMathOperator{\ZPP}{\bf{ZPP}}
\DeclareMathOperator{\Imm}{Im}
\DeclareMathOperator{\Mat}{Mat}
\DeclareMathOperator{\Dih}{D}


\newcommand{\OR}[1]{\operatorname{O} \bigl( #1 \bigr)}
%\newcommand{\cln}{\operatorname{O} ( #1 )}

\title{Matrix Group Recognition in MAGMA}
\date{2008-04-09}

\author{Henrik B\"a\"arnhielm}
\address{Department of Mathematics \\ University of Auckland \\ Auckland \\ New Zealand}
\urladdr{http://www.math.auckland.ac.nz/\textasciitilde henrik/}
\email{henrik@math.auckland.ac.nz}

\begin{document}

\begin{abstract}
Design ideas for a new $\MAGMA$ implementation of \texttt{CompositionTree}.
\end{abstract}

\maketitle

\section{General}

I will describe ideas for the design and implementation of a new
version of \lq\lq composition tree'' or ''matrix group recognition''
in $\MAGMA$, \emph{i.e.} the algorithm described in \cite{crlg01}.

The overall strategy is as in \cite{crlg01}, but new ideas
from \cite{statherthesis} and especially \cite{MR2289128} will be
used.

This first $\MAGMA$ implementation of this algorithm was done by
Eamonn O'Brien. The philosophy behind the new implementation is as follows:
\begin{itemize}
\item See the first implementation as a proof-of-concept and learn from it.
\item Incorporate software engineering thinking. In particular, the
  primary focus is \emph{extensibility} and \emph{maintainability}.
  Efficiency is a secondary goal.
\item Also from software engineering: object oriented programming is
  the best paradigm for larger software projects. Even though the
  $\MAGMA$ language is not really an OO language, one can simulate OO
  using the \texttt{rec} data structure. Since functions are
  first-class objects, one uses \texttt{UserProgram} record members to
  simulate OO object methods.
\item Use the recent features of the $\MAGMA$ language that was not
  available when the first implementation was made. In particular,
  make extensive use of the \texttt{AssociativeArray} data structure
  (hash table) and exception handling.
\item Implement a general composition tree algorithm that works for
  both matrix and permutation groups, using the theorems of Aschbacher
  and O'Nan-Scott, although the first and main issue are the matrix groups.
\item Use proper coding conventions. If variables and functions are
  named in a good way, code can be almost self-documenting, if one has
  a general knowledge of what it does.
\item Use proper code documentation. In the cases where comments are
  necessary in the code, they should really be comments, in other
  words concise. There is almost never a need of having long comments
  which explain what the code does, because the best such explanation
  is the code itself. An explanation of an algorithm is best done
  elsewhere, not as comments in the code.
\end{itemize}

\section{OO style data structure}

The algorithm manipulates a single data structure, a tree (also stored
as a sequence) made up of $\MAGMA$ records. Each node is represented
by a record, which is thought of as an OO class. This avoids assigning
lots of attributes to $\MAGMA$ group objects, they are all kept in a
single record. In keeping with OO thinking, the idea is that once the
data structure has been set up, one should only have to use variables
and functions in these records when manipulating the composition tree.
There should be a minimal need for calling other functions. Much like
an OO class, all data and methods are instead kept in one single place:
the record making up the data structure. This way the whole package
becomes more self-explanatory and easier to use.
One will not have to look through every source file to find the
correct function that computes whatever is at hand.

This central record is henceforth called \texttt{CTNodeData}. The
details of it is left to the code.

\section{Action database}

The central part of the algorithm is this:
\begin{enumerate}
\item Find a homomorphism $\varphi$ to an \lq\lq easier'' group,
  thereby reducing the problem, or deduce that the group is almost
  simple modulo scalars and perform constructive recognition.
\item Compute generators of the kernel of $\varphi$.
\end{enumerate}

One wants to avoid hard coding the use of the various algorithms that
finds homomorphisms, since this will be in a form of if-then
statements which can be difficult to extend and maintain. Instead we
use the ideas of \cite{MR2289128}. Keep an \lq\lq action database'' of
such algorithms, each with a certain rank and prerequisites. There is
one database for matrix groups, made up of the Aschbacher algorithms,
and one for permutation groups, made up the O'Nan-Scott algorithms.
Then one can have a general homomorphism finding algorithm that calls
the algorithms in this database in a certain order, specified in
\cite{MR2289128}. There is an attribute in \texttt{CTNodeData} where the result
of these calls are kept.

For example, in the matrix group case one has a function with very
high rank that calls the $\MAGMA$ intrinsic \texttt{IsIrreducible},
the MeatAxe. Then one has a function which calls
\texttt{IsAbsolutelyIrreducible}, but which will return \texttt{N/A}
unless \texttt{IsIrreducible} already has been called and returned
\texttt{true}. These functions therefore takes the current
\texttt{CTNodeData} as an argument so they can check which
homomorphism functions has been applied.

In $\MAGMA$, this is stored as an \texttt{AssociativeArray}. The keys
are the integer ranks, and the values are lists of functions. One
function tries to find a homomorphism, and returns a \texttt{BoolElt},
\texttt{fail} or \texttt{N/A}. Another function produces the
homomorphism as a \texttt{Map}, which is stored in the
\texttt{CTNodeData}. The \texttt{Map} must be defined by a rule, so
that one can apply \texttt{Function} to it.

The use of this hash table makes it much easier to change the
behaviour of the homomorphism finding functions. There is a single
place in the code where the \texttt{AssociativeArray} is defined. If
one wants to add more such functions, one can just add another entry
to the hash table, instead of having to edit a long and possibly
complicated if-then statement.

\section{Leaf database}

In principle, the various constructive recognition algorithms can be
put into the same action database. However, the leaves are handled
slightly differently, in that one always wants to name the leaf group
using \texttt{SimpleGroupName} before proceeding. Therefore the leaves
have a separate hash table, which is used in a similar style.

The keys are now the family name, as returned by
\texttt{SimpleGroupName}. For each family, we then have a another hash
table, where the keys are integer ranks. This is because one can have
a general black box algorithm for the whole family but also more
specialised ans faster algorithms which should be used in the cases
they apply. 

For example, if \texttt{SimpleGroupName} has returned \texttt{<A, 1,
  27>}, and the group we have is a matrix group over $\F_{3^3}$, then
we want to use \texttt{RecogniseSL2}. In other cases we want to use
\texttt{RecogniseSL}. Hence we have a function with high rank, which
calls the former intrinsic, but first verifies that the input is
suitable without any big computations. If the input is not a matrix
group over the correct field, then it returns \texttt{N/A}.

Again, the use of these hashtables makes the code easier to maintain
and understand. In the leaf case this is even more important, since
there is a much greater chance that we want to add more special cases
later. For example, one may want to use the ATLAS database for the
small finite fields that it covers. One can even easily add quick test
algorithms, by adding an entry to the hash table containing
\texttt{eval}'s of files which return functions.

\section{Exception handling}

A recent feature of the $\MAGMA$ language is rudimentary exception
handling. This should be used, because exceptions makes it possible to
first have a code block with the \lq\lq normal/error-free'' case, and
then have a code block that takes care of any errors. Without
exceptions, one has to check all the time if each step succeeded, and
only proceed if it did.

All functions encapsulating homomorphism finding or constructive
recognition should have try-catch blocks. In the case of errors, they
should throw \texttt{Error} objects and set the \texttt{Object}
attribute to a \texttt{Rec}, the \texttt{RecFrmt} depending on the
type of error. The members of the record should include information
about the type or error, so that the outer code that catches the error
can proceed accordingly.

The general homomorphism finding, the leaf routines and the main
recursive algorithm will work similarly.

\section{Other issues}

Some smaller design notes:
\begin{itemize}
\item Keep all constants centrally defined and never use numerals in
  the code. Often in the Las Vegas algorithms, one has to repeat a
  task a number of times before failing. These numbers should not be
  buried in the code, but always defined as properly named constants.

\item Encapsulate the handling of random elements properly, so that
  one can choose between the Prospector or standard product replacement.

\item One should have a choice between verification afterwards or
  during the creation of the composition tree, using presentations. In
  the latter case, one can take advantage of a deterministic
  computation of kernel generators. Also, there should be a choice to
  have a randomised verification after a presumed kernel has been
  found: at the beginning, computer an additional store of random
  elements (the so-called Mandarins) that are mapped around in the
  tree, and verify that they all lie in the kernel.

\item Use the method in \cite{statherthesis} to try to estimate the
  number of kernel generators.

\item When mapping elements around in the tree, always do it in
  batches, not element by element. When coming down to a leaf and
  expressing the elements as $\SLP$s, the leaf can in some cases
  produce a constant speed-up if it is supplied the whole batch. The
  reason is essentially that it internally can evaluate $\SLP$s
  faster, and when mapping the elements back to a parent, this same
  speed-up can be achieved if the $\SLP$s are evaluated all at once.

\end{itemize}

\bibliographystyle{amsalpha} 
\bibliography{mgrp}

\end{document}
