
///////////////////////////////////////////////////
// Collected notes and general comments that were 
// scattered through the package
///////////////////////////////////////////////////

A nonempty comment about CompactSystemOfEigenvalues
===================================================

I think I understand what you're suggesting, but let me repeat it
in my language to be sure.  Let M be the relevant space of modular
symbols and phi : M --> V the map defined by dotting a modular
symbol with each of a basis of left eigenvectors.   In
Algorithm 3.19 in my thesis, I compute a_p using

       a_p = <v, T_p(e)> / <v, e>,

where v is an eigenvector and e is a sparse vector.    Your observation
is that the map

           phi :  x |---> <v, x> / <v, e>  in Q(alpha)

is a linear map.   Moreover, ker(phi) is in the kernel of this map,
so psi induces an isomorphism PSI: V --> Q(alpha).   In Algorithm 3.19,
I compute PSI(phi(T_p(e))).  Your suggestion is to only compute phi(T_p(e)),
and then compute PSI(phi(T_p(e))) later, and only when necessary.

Your reason for only computing phi(T_p(e)) is that it's much easier to
write down than PSI(phi(T_p(e))).    So, for example, when making tables,
it's easier to store a pair:

       <The map PSI,  The elements phi(T_p(e))>

rather than storing the images of the elements under PSI, as I
currently do.  This would result in great space savings (a factor of
up to 100 sometimes, at least!) because the phi(T_p(e)) involve
significantly smaller numbers than PSI(phi(T_p(e))).

In any particular case, the user can apply PSI to phi(T_p(e)) to get
the sought for eigenvalue on a power basis, so nothing serious is
lost.   Also, if we compute all phi(T_n(e)), we've exactly written down
a basis of q-expansions for the space spanned by the Galois conjugates
of our eigenform.

So, great idea!  Now I wonder what I should do with the data in

  http://modular.fas.harvard.edu/Tables/aplist/eigenvalues_gamma0.html

...  I guess any good set of tables will go through several
iterations!  I can probably convert that data to your better format,
or just recompute everything to much higher precision.

